import os
import shutil
import subprocess
from web_search import search_duckduckgo

def ask_llm(user_query):
    # V√©rifie si Ollama est install√©
    if not shutil.which("ollama"):
        return "‚ùå Erreur : le programme 'ollama' n'est pas trouv√© sur le syst√®me."

    # Fait une recherche sur le Web avec SerpAPI
    web_info = search_duckduckgo(user_query)

    # Construit le prompt √† envoyer au mod√®le
    prompt = f"""
Tu es un assistant IA local. Voici des informations trouv√©es en ligne :

{web_info}

Ta t√¢che : r√©pondre de mani√®re claire √† cette question :
{user_query}

R√©ponse :
""".strip()

    try:
        print("üß† Prompt envoy√© √† Ollama :")
        print(prompt)

        # Lance le mod√®le avec subprocess + encodage UTF-8
        result = subprocess.run(
            ['ollama', 'run', 'mistral'],
            input=prompt.encode('utf-8'),         # encode en UTF-8
            capture_output=True                   # r√©cup√®re la r√©ponse
        )

        # V√©rifie s‚Äôil y a eu une erreur
        if result.returncode != 0:
            return f"‚ùå Erreur Ollama : {result.stderr.decode('utf-8', errors='ignore')}"

        # Renvoie la r√©ponse correctement d√©cod√©e
        return result.stdout.decode('utf-8', errors='ignore').strip()

    except Exception as e:
        return f"‚ùå Erreur ex√©cution via subprocess : {str(e)}"
